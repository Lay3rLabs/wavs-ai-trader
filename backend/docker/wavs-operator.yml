services:
  wavs:
    image: "${COMPOSE_WAVS_DOCKER_IMAGE:-}"
    container_name: "${COMPOSE_PROJECT_NAME:-}"
    stop_signal: SIGKILL
    environment:
      - WAVS_SUBMISSION_MNEMONIC=${WAVS_OPERATOR_MNEMONIC:-}
      - RUST_LOG=${WAVS_LOG_LEVEL:-}
      - WAVS_LOG_LEVEL=${WAVS_LOG_LEVEL:-}
      - WAVS_ENV_COINGECKO_API_KEY=${WAVS_ENV_COINGECKO_API_KEY:-}
      - WAVS_ENV_SKIP_API_KEY=${WAVS_ENV_SKIP_API_KEY:-}
    command:
      [
        "wavs",
        "--home",
        "/wavs-home",
        "--data",
        "/var/${COMPOSE_PROJECT_NAME:-}",
        "--port",
        "${COMPOSE_WAVS_PORT:-}",
      ]
    volumes:
      - "${COMPOSE_WAVS_HOME:-}:/wavs-home"
    network_mode: "host"

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    stop_signal: SIGKILL
    environment:
      HSA_OVERRIDE_GFX_VERSION: "11.0.0"
      HIP_VISIBLE_DEVICES: "0"
    # devices:
    #   - "/dev/kfd"
    #   - "/dev/dri"
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    ipc: host
    group_add:
      - video
    volumes:
      - ./.docker/data_ollama:/root/.ollama
      - ./.docker/ollama.entrypoint.sh:/entrypoint.sh
    network_mode: "host"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    # command: serve
    # Auto-pull models on startup
    entrypoint: ["/bin/bash", "/entrypoint.sh"]    